{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02408ca8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Tokenization\n",
    "Ziel der Tokenization ist es, gegebene Zeichenketten zu zerlegen. So werden Sätze oder Wörter in sogenannte Tokens aufgeteilt, um sie weiterverarbeiten zu können."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eac19c5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Inhaltsverzeichnis\n",
    "- [Vorbereitung](#Vorbereitung)\n",
    "- [Ein naiver Ansatz](#Ein-naiver-Ansatz)\n",
    "- [Tokenizer aus NLTK](#Tokenizer-aus-NLTK)\n",
    "- [Behandlung deutscher Texte](#Behandlung-deutscher-Texte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76577046",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Vorbereitung\n",
    "Zuerst laden wir die Bibliothek `nltk`. `nltk` steht für *Natural Language Toolkit* und ist eine der am weitesten verbreiteten Bibliotheken zur Verarbeitung von natürlicher Sprache. Sie stellt einfache Schnittstellen bereit, um mit verschiedenen Modellen in verschiedenen Sprachen zu arbeiten.\n",
    "\n",
    "Bei der Installation der Bibliothek werden die benötigten Modelle übrigens noch nicht installiert. Stattdessen müssen Sie diese separat durch einen Aufruf der Funktion `download` herunterladen. Als Parameter wählen Sie entweder den Namen des Pakets, das Sie benötigen, oder `all`, um alle (3,5 GB) auf Ihrem Computer zu speichern.\n",
    "\n",
    "**Hinweis**: Im Docker-Image sind auf Grund der Größe nur die für diese Vorlesung relevanten Pakete enthalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa64589e",
   "metadata": {
    "deletable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b30a95",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Ein naiver Ansatz\n",
    "Mithilfe der Python-Funktion `split` lassen sich Zeichenketten an bestimmten Stellen aufteilen. Die sich ergebenden Segmente werden ihrerseits als eine Liste von Zeichenketten zurückgegeben.\n",
    "\n",
    "Der erste Parameter gibt dabei an, bei welchem Zeichen getrennt werden soll. Der Standardwert für diesen Parameter ist das Leerzeichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d22e0",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "\"I can't put my hat back on.\".split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3001d02",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die Wörter sind offenbar voneinander getrennt. Allerdings ist diese Lösung nicht im engeren Sinne korrekt. So finden Sie mehrere Wörter, die Satzzeichen oder öffnende bzw. schließende Klammern enthalten. Für Anführungszeichen und Apostrophe gilt im Übrigen das selbe.\n",
    "\n",
    "Leider ist es nicht möglich, alle Zeichen außer Buchstaben aus den einzelnen Elementen der Liste zu entfernen. Der Punkt als Satzzeichen markiert beispielsweise im Deutschen Abkürzungen und Ordinalzahlen und sollte demnach in genau diesen Fällen erhalten bleiben, um den Sinn einer Aussage nicht zu verfälschen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c6f1b4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Tokenizer aus NLTK\n",
    "NLTK liefert verschiedene Funktionen mit, um einen Text in Tokens zu verwandeln."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5893df82",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### WhitespaceTokenizer\n",
    "Der grundlegenste Tokenizer ist der `WhitespaceTokenizer`. Dieser teilt Sätze anhand von Leerzeichen, Zeilenumbrüchen und Tabstopps. Das Ergebnis verhält sich also analog zu unserem naiven Ansatz, der die in Python integrierte Funktion `split` verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75039650",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "WhitespaceTokenizer().tokenize(\"I can't put my hat back on.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ac5522",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### sent_tokenize\n",
    "Die erste Funktion, die eine deutlich komplexere Implementierung einschließt, heißt `sent_tokenize` und unterteilt einen Text in einzelne Sätze. Dabei wird automatisch der von NLTK empfohlene Tokenizer verwendet. (Demnach kann also das Ergebnis unter verschiedenen Versionen von NLTK varrieren!) Dieser Tokenizer ist bereits ausgefeilt genug, um nicht jeden einzelnen Punkt als das Ende eines Satzes zu betrachten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d004814f",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokenize(\"I can't put my hat back on. Mr. X told me so.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172dc101",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### word_tokenize\n",
    "Aber auch innerhalb von Sätzen kann NLTK eine deutlich komplexere Tokenization vornehmen. Die Funktion `word_tokenize` unterteilt einen Satz in die einzelnen Wörter. Das Ergebnis der Tokenization ist dabei deutlich näher an der Bedeutung der Worte als die Teilung an Leerzeichen, wie sich insbesondere durch die Trennung von *ca* und *n't* zeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4221649e",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(\"I can't put my hat back on.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c640b876",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Auch der Punkt wird nicht einfach dem letzten Wort des Satzes zugeordnet. Punkte, die Abkürzungen markieren, bleiben dagegen am zugehörigen Wort hängen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bea954",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "word_tokenize('Mr. X told me so.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d66552b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### SyllableTokenizer\n",
    "Auch das Aufteilen in Silben beherrscht NLTK. Dazu kann beispielsweise der `SyllableTokenizer` verwendet werden. Die übergebene Zeichenkette darf jedoch nur einzelne Wörter enthalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072c111a",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from nltk import SyllableTokenizer\n",
    "SyllableTokenizer().tokenize(\"comprehension\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe217d9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Behandlung deutscher Texte\n",
    "Westliche Sprachen trennen in der Regel ihre Wörter durch Leerzeichen und auch die Interpunktion funktioniert ähnlich. Mit der Standardeinstellung - Englisch - lassen sich daher auch die meisten deutschen Sätze problemlos verarbeiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f1c2c2",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "word_tokenize(\"Sei's viehisches Vergessen oder sei's ein banger Zweifel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f47779",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Sollten Sie dennoch einmal mit dem Ergebnis unzufrieden und der Unterschied zwischen den Sprachen dafür verantwortlich sein, so können Sie auch die verwendete Sprache setzen. NLTK unterstützt über ein Dutzend Sprachen, aus denen Sie mit Hilfe des Parameters `language` wählen können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57261310",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "word_tokenize(\"Sei's viehisches Vergessen oder sei's ein banger Zweifel\", language='german')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
