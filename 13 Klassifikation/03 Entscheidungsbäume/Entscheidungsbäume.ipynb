{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a48f479",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Entscheidungsbäume\n",
    "Entscheidungsbäume stellen eine Form der Klassifikation dar, die nicht auf das vollständige Abspeichern aller zum Training verwendeter Beispiele angewiesen ist. Durch Untersuchung der Attribute werden solche ausgewählt, die eine möglichst gute Unterteilung ermöglicht, bis auf Klassen geschlossen werden kann.\n",
    "\n",
    "Laden Sie zuerst die benötigten Funktionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c456c2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902ffc2c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Inhaltsverzeichnis\n",
    "- [Einleitung](#Einleitung)\n",
    "- [Splits](#Splits)\n",
    "- [Konstruktion des Baumes](#Konstruktion-des-Baumes)\n",
    "- [Beispiel mit Trainingsdaten](#Beispiel-mit-Trainingsdaten)\n",
    "- [Implementierung in `scikit-learn`](#Implementierung-in-scikit-learn)\n",
    "- [Random Forest](#Random-Forest)"
   ]
  },
  {
   "attachments": {
    "1.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "d55251ca",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Einleitung\n",
    "Stellen Sie sich vor einen Ausflug zu planen. Anhand des Wetterberichts ist für jeden der kommenden Tage bekannt, wie sich Aussicht, Temperatur, Feuchtigkeit und Wind entwickeln. Um zu klassifizieren, ob ein Tag für den Ausflug geeignet sein wird, könnten Sie beispielsweise mehrere Attribute jedes einzelnen Tages in Folge bewerten.\n",
    "\n",
    "![Entscheidungsbaum](attachment:1.png)\n",
    "\n",
    "Im gegebenen Beispiel ist auch direkt ersichtlich, warum diese Art des Klassifikators als Entscheidungs**baum** bezeichnet wird. Diese Darstellung unterstreicht nämlich die hierarchisch angeordneten Regeln, die von der Wurzel zu den entfernten Blättern durchlaufen werden. Die Blätter - Knoten ohne Kinder - stellen die Klassen dar. Es müssen dabei nicht alle Attribute verwendet werden. Die Temperatur wurde beispielsweise nicht als entscheidendes Attribut in den Entscheidungsbaum übernommen.\n",
    "\n",
    "Im Gegensatz zu diesem einfachen Beispiel, das sich mit niedrig-dimensionalen Daten an offensichtlichen Erfahrungswerten orientiert, ist die Erstellung eines Entscheidungsbaumes für komplexe Datensätze nicht immer von Hand möglich. Zumindest aber sind bei komplexen Fragestellungen Experten notwendig."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865ea124",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Splits\n",
    "Um automatisiert einen Entscheidungsbaum erstellen zu können ist es nun also notwendig, Kriterien für die Relevanz einer Aufteilung, auch Split genannt, zu finden. Diese Splits können entweder zu zwei (binär) oder mehr Verzweigungen führen. Dabei werden sie abhängig vom Typ des Attributs als kategorisch oder numerisch bezeichnet. Um die Anzahl der Verzweigungen zu reduzieren, kann es lohnenswert sein, numerische Attribute zu diskretisieren. (Dazu können Sie beispielsweise die Funktion `cut` aus Pandas verwenden.)\n",
    "\n",
    "Ziel eines Splits sollte sein, die Menge aller Beispiele in möglichst wenigen Schritten zu teilen, bis Mengen mit ausschließlich einer einzelnen Klasse übrig bleiben. Es wird daher versucht, möglichst früh ein Attribut zu wählen, das *reine* Splits erzeugt. (*Rein* bedeutet in diesem Kontext, dass alle Elemente der entstandenen Menge die selbe Klasse besitzen.)\n",
    "\n",
    "Zuerst wird also ein Maß für die Unreinheit benötigt. Der sogenannte Gini-Index - benannt nach Corrado Gini - kann für eine Partition von Trainingsobjekten wie folgt berechnet werden. Dabei ist $k$ die Anzahl an Klassen, $T$ eine Menge von Trainingsobjekten und $C_i \\subseteq T$ genau die Teilmenge, die der $i$-ten Klasse zugeordnet wird.\n",
    "\n",
    "$$\n",
    "gini(T) = 1 - \\sum_{i=1}^{k}\\left(\\dfrac{|C_i|}{|T|}\\right)^2\n",
    "$$\n",
    "\n",
    "Anhand einiger Beispiele lässt sich feststellen, dass der Wert am größten ist, wenn die Elemente über alle Klassen gleichverteilt sind. Ein niedriger Wert spricht dagegen für eine hohe Reinheit. Im Falle binärer Splits lässt sich die Gleichung wie folgt in Python ausdrücken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831bf809",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def gini(T):\n",
    "    return 1 - (len(T[T['class'] == 0]) / len(T)) ** 2 - (len(T[T['class'] == 1]) / len(T)) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a29015",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Als nächstes wird ein Maß benötigt, das ein Attribut $A$ beispielsweise anhand des Gini-Index bewertet. Stellen Sie sich nun vor, dass das Attribut die Menge aller Trainingsbeispiele $T$ in mehrere Teilmengen $T_1, \\dots, T_m$ zerlegt. Durch das Attribut Feuchtigkeit entstehen dabei beispielsweise die zwei Teilmengen $T_1$ (normal) und $T_2$ (hoch). Der Gini-Index wird anschließend anhand des relativen Anteils der Teilmenge gewichtet und zur Bewertung des Attributs herangezogen.\n",
    "\n",
    "$$\n",
    "gini_A(T) = \\sum_{i=1}^{m}\\dfrac{|T_i|}{|T|}*gini(T_i)\n",
    "$$\n",
    "\n",
    "Auch dieser Wert ist so konstruiert, dass ein Ergebnis nahe $0$ für eine hohe Reinheit spricht. In Python lässt sich diese Gleichung ebenfalls ausdrücken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d25779",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def gini_A(T, A):\n",
    "    T1, T2 = T[T[A] == 0], T[T[A] == 1]\n",
    "    if len(T1) == 0 or len(T2) == 0:\n",
    "        return 1\n",
    "\n",
    "    return len(T1) / len(T) * gini(T1) + len(T2) / len(T) * gini(T2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d851f7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die Bewertung des Splits ist nicht nur mit dem Gini-Index möglich. Alternativ lässt sich beispielsweise die Entropie verwenden, um ein Gütekriterium aufzustellen. Um die nachfolgende Funktion `construct_tree` zu verstehen, genügt der Gini-Index jedoch vollkommen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0114c985",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Konstruktion des Baumes\n",
    "Die rekursive Funktion `construct_tree` erhält zwei Parameter. `T` bezeichnet die Trainingsmenge und `min_conf` die minimale Konfidenz. Der Ablauf gestaltet sich wie folgt:\n",
    "\n",
    "1. Wenn die Konfidenz der Menge `T` die minimale Konfidenz überschreitet, endet der Aufruf.\n",
    "2. Für jedes Attribut wird\n",
    "    1. jeder mögliche Split\n",
    "      - betrachtet und bewertet.\n",
    "3. Der beste gefundene Split wird durchgeführt.\n",
    "4. Die Teilmengen $T_1, \\dots, T_m$ sind die durch diesen Split entstehenden Partitionen von T.\n",
    "5. Für jede Teilmenge $T_1, \\dots, T_m$ wird die Funktion `construct_tree` rekursiv aufgerufen.\n",
    "\n",
    "Die folgende Funktion demonstriert den Ablauf ausschließlich für binäre Splits. Weiter unten werden Sie eine komplexere Funktion aus `scikit-learn` sehen, die auch für numerische Attribute geeignet ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f47e735",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def construct_tree(T, min_conf):\n",
    "    # Zuerst wird die Anzahl der Objekte jeder der zwei\n",
    "    # möglichen Klassen bestimmt und gespeichert.\n",
    "    count_0 = len(T[T['class'] == 0])\n",
    "    count_1 = len(T[T['class'] == 1])\n",
    "\n",
    "    # Die minimale Konfidenz bildet die Abbruchbedingung.\n",
    "    if count_0 / len(T) >= min_conf:\n",
    "        return 0\n",
    "    if count_1 / len(T) >= min_conf:\n",
    "        return 1\n",
    "\n",
    "    # Anhand des Gini-Index wird das geeignetste Attribut\n",
    "    # `A` gesucht. Der Split ist bei binären Entscheidungen\n",
    "    # automatisch gegeben und muss nicht zusätzlich gefunden\n",
    "    # werden.\n",
    "    min_A = None\n",
    "    min_score = 2\n",
    "\n",
    "    for A in T.drop('class', axis=1):\n",
    "        score = gini_A(T, A)\n",
    "        if score < 1 and score < min_score:\n",
    "            min_A = A\n",
    "            min_score = score\n",
    "\n",
    "    # Wenn kein Attribut gefunden werden konnte, wird die\n",
    "    # Klasse zurückgegeben, der mehr Objekte angehören.\n",
    "    if min_A is None:\n",
    "        if count_0 >= count_1:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    # Falls ein Attribut gefunden wurde, wird der Split\n",
    "    # durchgeführt. Bei binären Splits entstehen immer genau\n",
    "    # zwei neue Teilmengen.\n",
    "    T1 = T[T[min_A] == 0]\n",
    "    T2 = T[T[min_A] == 1]\n",
    "\n",
    "    # Für jede dieser Teilmengen wird die Funktion\n",
    "    # `construct_tree` rekursiv aufgerufen.\n",
    "    # Zurückgegeben wird ein Tupel der Form\n",
    "    # (Attribut, Baum oder Klasse für 0, rechter Baum oder Klasse für 1).\n",
    "    return min_A, construct_tree(T1, min_conf), construct_tree(T2, min_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bb1815",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Beispiel mit Trainingsdaten\n",
    "Um einen ersten Entscheidungsbaum zu konstruieren, verwenden wir den Datensatz [banknote authentication Data Set](https://archive.ics.uci.edu/ml/datasets/banknote+authentication). Enthalten sind verschiedene Features, die aus Aufnahmen von Geldscheinen extrahiert wurden, und eine Klasse, welche die Authentizität der Note repräsentiert.\n",
    "\n",
    "Da der Algorithmus zunächst nur mit binären Entscheidungen arbeitet, wird eine konvertierte Version geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c6e344",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "df_binary = pd.read_csv('data_banknote_authentication_binary.csv', sep=',')\n",
    "df_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e71c57",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Mit diesem DataFrame wird anschließend die Funktion `construct_tree` aufgerufen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380f97e8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "df_tree = construct_tree(df_binary, 0.9)\n",
    "df_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0188a5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Das entstandene, gestaffelte Tupel können Sie bereits von Hand auswerten und einige Beispiele damit klassifizieren. Die folgende Zelle stellt es abschließend als tatsächlichen Baum dar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370978b6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from tree import draw\n",
    "draw(df_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f59b3f7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Anhand der Baumdarstellung lässt sich auch einer der größten Vorteile von Entscheidungsbäumen erkennen. Man kann bis zu einer gewissen Komplexität die Entscheidungen nachvollziehen und leicht vermitteln."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf1fc9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Implementierung in `scikit-learn`\n",
    "`scikit-learn` bietet wie so oft eine fertige Implementierung für die Erstellung eines Entscheidungsbaums. Diese Funktion akzeptiert auch numerische Daten und findet ohne weitere Informationen die besten Splits. Zuerst wird daher der vollständige Datensatz geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ac9de9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_banknote_authentication.csv', sep=',')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b6eb18",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Zum Training ist es zuerst notwendig, die Daten in Features und Klassen zu teilen. Dazu werden zwei DataFrames erzeugt, wobei das erste alle Spalten außer `class` und das zweite ausschließlich die Spalte `class` enthält. Bei werden anschließend der Methode `fit` eines Objekts der Klasse `DecisionTreeClassifier` übergeben. Die erlernten Splits werden in diesem Objekt gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff16ae",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X, y = df.drop('class', axis=1), df[['class']]\n",
    "tree = DecisionTreeClassifier().fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08299cd0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Mit `plot_tree` steht außerdem eine Funktion bereit, die den entstandenen Baum grafisch darstellt. Verwenden Sie `pass` als letzte Anweisung in der Zelle, um die Ausgabe der exakten Koordinaten zu unterdrücken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c528a5f5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plot_tree(tree)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4544ee83",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Random Forest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
