{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8343182",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Evaluation\n",
    "Wie bereits beim Clustering gibt es Maße, die eine Aussage über die Leistung eines Klassifikators in einen numerischen Wert fassen. In diesem Abschnitt sollen Ihnen mehrere dieser Maße anhand eines Beispiels gezeigt werden.\n",
    "\n",
    "Die ersten Code-Zellen laden Pandas und den Datensatz [weight-height.csv](https://www.kaggle.com/datasets/mustafaali96/weight-height), den Sie bereits aus der Einleitung dieses Kapitels kennen. Die Spalte `gender` wird zudem in ein numerisches Attribut transformiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d22a07e",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from tui_dsg.datasets import weightheight_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1523d9-64dd-4f09-a34c-c1808736b2e4",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(weightheight_path)\n",
    "px.scatter(df, x='weight', y='height', color='gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d7fe5c-c136-43a2-bd0e-8ebf93e00a04",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "df['gender'] = df['gender'].map({'f': 0, 'm': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d48da31",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Inhaltsverzeichnis\n",
    "- [Trainings- und Testdaten](#Trainings--und-Testdaten)\n",
    "- [Training des Klassifikators](#Training-des-Klassifikators)\n",
    "- [Genauigkeit](#Genauigkeit)\n",
    "- [Detaillierter Wahrheitsgehalt von Vorhersagen](#Detaillierter-Wahrheitsgehalt-von-Vorhersagen)\n",
    "- [Precision](#Precision)\n",
    "- [Recall](#Recall)\n",
    "- [Kompromisse](#Kompromisse)\n",
    "- [F1-Maß](#F1-Maß)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5b729c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Trainings- und Testdaten\n",
    "Bisher wurden die Daten ausschließlich zum Training verwendet. Um jedoch den Erfolg des Lernens bewerten zu können, müssen zusätzlich annotierte Testdaten bereitstehen. Im einfachsten Fall wird dazu eine Menge bekannter Daten vor dem Lernen des Klassifikators in Trainings- und Testdaten aufgeteilt aufgeteilt werden. Die hilfreiche Funktion `train_test_split` stammt aus dem Paket `scikit-learn` und kann sowohl NumPy Arrays wie auch Pandas DataFrames aufteilen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771ae298",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size=0.25)\n",
    "\n",
    "len(df_train), len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9d3ab8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Den Namen entsprechend wird der Trainingsdatensatz für das Training und der Testdatensatz für die Überprüfung des Lernerfolgs eingesetzt. Verwenden Sie die selbe Menge für beide Schritte, besteht die Möglichkeit, dass der Klassifikator den Trainingsdatensatz \"auswendig lernt\" und damit eine sehr gute Wertung mit diesen Beispielen erreicht. Stattdessen soll der Klassifikator jedoch verallgemeinern, sodass auch neu hinzukommende, unbekannte Daten korrekt eingeordnet werden.\n",
    "\n",
    "Stellen Sie sich analog einen Studenten vor, der für eine bevorstehende Prüfung lernt. Alte Klausuren dienen dabei als Trainingsdatensatz. Gibt es nur wenige Aufgaben, kann auswendig lernen und wiedergeben der alten Lösungen effizienter sein als sie zu verstehen und den Lösungsansatz zu verallgemeinern. Nach einer bestandenen Prüfung erwartet man in aller Regel jedoch genau letzteres - Lösungsstrategien sollten auf neue Probleme angewendet werden können. Prüfer werden sich also davor hüten, die Bewertung von Aufgaben abhängig zu machen, die dem Lernenden alle bereits zur Verfügung standen.\n",
    "\n",
    "Gerade im Bereich des tiefen Lernens geschieht es jedoch schnell, dass die Netzkapazität ausreicht, um auch zunächst umfangreich erscheinende Mengen an Trainingsdaten auswendig zu lernen. Man spricht dann von *Overfitting*. Wenn der Fehler bei der Klassifikation von Trainingsbeispielen kontinuierlich sinkt, während er in Zusammenhang mit den Testbeispielen steigt, ist dies ein starkes Indiz. (Der Prüfling wäre in diesem Fall im Stande alle alten Klausuren zügig zu lösen und würde trotzdem durchfallen.)\n",
    "\n",
    "Zu welchen Anteilen Trainings- und Testdaten gewählt werden sollten hängt indes stark von deren Anzahl, der Komplexität des Klassifikators, der gewählten Lernmethode und weiteren Faktoren ab. Beim tiefen Lernen wird gelegentlich sogar eine dritte Teilmenge zur Validierung der Parameter genutzt. Im Allgemeinen ist eine Aufteilung, die grob $75$ Prozent des Datensatzes den Trainingsdaten zuordnet, ein guter Anfang.\n",
    "\n",
    "Achten Sie zudem darauf, dass die Daten vor der Aufteilung zufällig gemischt werden. Sind bei der Erhebung zuerst Frauen und anschließend Männer untersucht worden und sie wählen das letzte Viertel als Testdatensatz, enthält dieser ansonsten nur die Werte der Herren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee1f288",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Training des Klassifikators\n",
    "Um die Leistung des Klassifikators zu bewerten, kommt als Beispiel ein Nächster-Nachbar-Klassifikator zum Einsatz. Dieser wird anhand der Trainingsdaten lernen und anschließend anhand der Testdaten bewertet. Die nachfolgende Zelle definiert jedoch nur eine Funktion, die Training und Bewertung übernimmt, sodass Sie bei jedem Gütemaß die Möglichkeit haben, interaktiv die Auswirkung des Parameters `n_neighbors` zu erkunden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adf2520",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def fit_and_predict(n, test_data=df_test):\n",
    "    nn = KNeighborsClassifier(n_neighbors=n).fit(df_train[['weight', 'height']], df_train['gender'])\n",
    "    prediction = nn.predict(test_data[['weight', 'height']])\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604626ef",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Genauigkeit\n",
    "Die Genauigkeit ist das einfachste Maß zur Bewertung eines Klassifikators. Sie gibt den relativen Anteil der korrekt klassifizierten Objekte an und ist damit sehr einfach zu berechnen. Sie können dazu eine Funktion aus dem Paket `scikit-learn` verwenden, die $1$ bei einer perfekten Klassifikation und $0$ bei keinerlei richtigen Ergebnissen zurückgibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7ba121",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "@interact(n=IntSlider(3, 1, 30, 1))\n",
    "def _(n):\n",
    "    return accuracy_score(df_test['gender'], fit_and_predict(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd831a3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Verständnisfrage**: Für welches $n$ liefert der Klassifikator beim Trainingsdatensatz eine möglichst hohe Genauigkeit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a40c16",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "@interact(n=IntSlider(3, 1, 30, 1))\n",
    "def _(n):\n",
    "    return accuracy_score(df_train['gender'], fit_and_predict(n, test_data=df_train))"
   ]
  },
  {
   "attachments": {
    "1.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "23dfd634",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Detaillierter Wahrheitsgehalt von Vorhersagen\n",
    "Die Annahme, eine Vorhersage könnte lediglich falsch oder korrekt liegen, mag schlüssig sein, greift aber zu kurz. Im Folgenden unterteilen wir am Beispiel der binären Klassifikation mit zwei Klassen sowohl richtige wie falsche Vorhersagen jeweils in zwei Unterkategorien. Diese Kategorisierung ist dabei abhängig von der getroffenen Vorhersage wie von der tatsächlichen Klasse eines Objekts.\n",
    "\n",
    "![Wahrheitstabelle](attachment:1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2725060d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Precision\n",
    "*Precision* gibt als Maß an, wie viele der als wahr vorhergesagten Objekte tatsächlich diese Klasse besitzen. Umgekehrt könnte man es als Fähigkeit des Klassifikators bezeichnen, Beispiele nicht als wahr zu bewerten, die tatsächlich negativ sind. Auf Basis der getroffenen Einteilung berechnet sich die Precision wie folgt.\n",
    "\n",
    "$$\n",
    "P = \\dfrac{TP}{TP+FP}\n",
    "$$\n",
    "\n",
    "Auch für die Precision existiert eine Funktion in `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b12bccb",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "@interact(n=IntSlider(3, 1, 30, 1))\n",
    "def _(n):\n",
    "    return precision_score(df_test['gender'], fit_and_predict(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75c9b22",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Recall\n",
    "*Recall* oder auch *Trefferquote* gibt als Maß an, wie viele der wahren Beispiele durch den Klassifikator tatsächlich aufgedeckt wurden. Auf Basis der getroffenen Einteilung berechnet sich der Recall wie folgt.\n",
    "\n",
    "$$\n",
    "R = \\dfrac{TP}{TP+FN}\n",
    "$$\n",
    "\n",
    "Auch für den Recall existiert eine Funktion in `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fe5b33",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "@interact(n=IntSlider(3, 1, 30, 1))\n",
    "def _(n):\n",
    "    return recall_score(df_test['gender'], fit_and_predict(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7146ac",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Kompromisse\n",
    "In realen Szenarien werden Precision und Recall niemals gleichzeitig $1$ sein. Es gestaltet sich dagegen eher so, dass eine Optimierung immer einen Kompromiss beider Werte zur Folge hat. Ohne einen starken Rückgang des jeweils anderen Wertes lassen sich beide nicht perfektionieren.\n",
    "\n",
    "Stellen Sie sich beispielsweise vor, dass Patienten als gesund oder krank klassifiziert werden sollen. Personen mit schwachen Symptomen könnten beispielsweise als gesund (aber übermüdet) eingestuft werden, sodass der Recall sinkt. Diese Patienten dennoch ausnahmslos als krank zu betrachten, wird immer einige einschließen, die tatsächlich nur stark erschöpft sind, sodass die Precision sinkt.\n",
    "\n",
    "Allerdings ist es natürlich je nach Problem sogar notwendig, einseitig zu optimieren. Wird eine Vorauswahl für die Beschädigung sicherheitsrelevanter Bauteile getroffen, ist es vermutlich besser, $100$ Fälle an einen menschlichen Experten zu übergeben als auch nur ein defektes Teil in einem Hochgeschwindigkeitszug zu verbauen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d048b34",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## F1-Maß\n",
    "Das F1-Maß ist das harmonische Mittel aus Precision und Recall. Diese beiden Werte fließen also zu gleichen Teilen in das Ergebnis ein. Ob diese Gewichtung erwünscht ist, hängt erneut von der Problemstellung ab.\n",
    "\n",
    "$$\n",
    "F_1 = 2 * \\dfrac{P*R}{P+R}\n",
    "$$\n",
    "\n",
    "Natürlich stellt `scitkit-learn` auch für das F1-Maß eine Funktion bereit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8031a620",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "@interact(n=IntSlider(3, 1, 30, 1))\n",
    "def _(n):\n",
    "    return f1_score(df_test['gender'], fit_and_predict(n))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
